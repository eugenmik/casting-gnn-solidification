# AI-Driven Casting Solidification: Deep GNN Solver

## Overview
This project presents an R&D prototype for predicting the solidification process in complex 3D castings using **Graph Neural Networks (GNN)**. By leveraging geometric deep learning, this solver aims to provide near-instantaneous thermal analysis, significantly reducing the computational time compared to traditional CAE tools like Magma or ProCAST.

The model is specifically designed to identify thermal centers (hotspots) in massive casting sections (e.g., X-nodes) by simulating the cooling gradient from the surface to the core.

---

## Methodology

### 1. Synthetic Dataset Generation
A custom pipeline was developed to generate a massive dataset of 3D casting primitives:
* **Procedural CAD Modeling:** 9,710 unique 3D geometries were procedurally generated using the **CadQuery** library.
* **Volumetric Meshing:** High-quality tetrahedral meshes were produced in **Gmsh**.
* **Boundary Condition Labeling:** Surfaces were labeled to distinguish between **Diabatic** (heat exchange through molding sand) and **Adiabatic** (insulated) boundaries.

### 2. Thermal Simulation (Ground Truth)
"Ground Truth" data was established through high-fidelity thermal simulations:
* **Material:** Ductile Iron **EN-GJS-500**.
* **Initial Conditions:** Pouring temperature set at **1380°C**.
* **Simulation Scope:** Conducted until complete crystallization (solidification).
* **Data Format:** Results captured in temporal scalar snapshots (.npz) and geometry meshes (.msh).

### 3. GNN Architecture & Physics Logic
This project implements an **Autoregressive Delta-Prediction** strategy to honor the physics of heat diffusion:
* **Input Features ($N=8$):** Coordinates ($x, y, z$), one-hot boundary markers, current temperature ($T_t$), and the **Signed Distance Function (SDF)** to the nearest boundary.
* **Delta-Logic:** The GNN predicts the temperature change $\Delta T$ between consecutive frames:
  $$T_{t+1} = T_t + \Delta T_{pred}$$
* **Deep Processor:** A **MeshGraphNet** with **12-15 Processor layers** and Residual Connections ensures thermal signals propagate into the center of massive sections.



---

## Project Structure
```
casting-gnn-solidification/
├── data/                   # Raw .msh and .npz files (9,710 pairs)
├── data_pyg/               # Processed .pt binary files for PyG
├── weights/                # Saved model checkpoints
├── src/                    # Core logic
│   ├── model.py            # MeshGraphNet architecture
│   ├── dataset.py          # CastingDataset with SDF calculation
│   └── train.py            # Delta-learning training loop
├── convert_to_pyg.py       # Data integration script
├── main.py                 # Training entry point
├── visualize.py            # PyVista-based interactive visualizer
├── environment.yml         # Conda environment configuration
└── README.md
```
## Installation & Setup

Follow these steps to set up the environment and prepare the data for training.

### 1. Prerequisites
Ensure you have the following installed:
* **Miniconda** or **Anaconda**.
* **Git** (for cloning the repository).
* **NVIDIA GPU** with CUDA support is highly recommended for training the 12-layer MeshGraphNet.

### 2. Clone the Repository
```
git clone [https://github.com/your-username/casting-gnn-solidification.git](https://github.com/your-username/casting-gnn-solidification.git)
cd casting-gnn-solidification
```
### 3. Environment Setup

This project requires a specialized Python environment to handle geometric deep learning and 3D mesh processing. We use **Conda** for dependency management.

#### A. Automated Installation
The easiest way to set up the environment is to use the provided `environment.yml` file, which includes all necessary libraries such as `torch`, `torch-geometric`, `meshio`, `pyvista`, and `cadquery`:

```
# Create the environment from the configuration file
conda env create -f environment.yml

# Activate the specialized environment
conda activate cast_gnn
```
#### B. Manual Dependency Overview

If you prefer to install the packages individually, ensure your environment includes the following core dependencies:

* **Python 3.10+**: The base language for the entire pipeline.
* **PyTorch & PyTorch Geometric (PyG)**: The engine for GNN architecture and deep message passing on tetrahedral meshes.
* **Meshio**: Essential for reading and processing `.msh` files generated by Gmsh during the data conversion stage.
* **PyVista**: Used for high-performance 3D visualization, including real-time thermal thresholding and "Liquid Core" rendering.
* **CadQuery**: Required for the procedural generation of the 9,710 unique 3D casting primitives.
* **Gmsh**: Used for volumetric tetrahedral meshing and defining diabatic/adiabatic boundary markers.
* **NumPy & TQDM**: For efficient numerical operations and progress tracking during large-scale data conversion.

> **Note:** For GPU acceleration, ensure your `torch` installation is compatible with your installed **CUDA** version (recommended: CUDA 11.7 or 11.8).

#### C. Hardware Requirements

To achieve efficient training and real-time visualization of the deep **MeshGraphNet** architecture, the following hardware specifications are recommended:

* **Graphics Processing Unit (GPU):** A dedicated **NVIDIA GPU** with CUDA support is mandatory for deep message passing and gradient calculations.
* **Video RAM (VRAM):** At least **8GB to 12GB** of VRAM (e.g., **NVIDIA RTX 3060 12GB**) is required to handle the memory overhead of 12-15 processor layers when operating on complex tetrahedral meshes.
* **System Memory (RAM):** A minimum of **16GB-32GB** of RAM is recommended to ensure smooth data conversion and mesh processing via `Meshio` and `CadQuery`.
* **Storage Capacity:** Approximately **50GB-100GB** of free disk space is required to store the 9,710 raw simulation pairs (`.msh` and `.npz`) along with the processed PyTorch Geometric datasets.

> **Note:** While the model can run on a CPU for inference (prediction), training is not feasible on a CPU due to the iterative nature of the **Delta-Prediction** logic and the depth of the graph processor.